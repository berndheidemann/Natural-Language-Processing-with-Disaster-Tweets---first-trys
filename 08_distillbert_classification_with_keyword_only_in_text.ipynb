{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle=False\n",
    "kaggle_path='/kaggle/input/nlp-getting-started/train.csv'\n",
    "local_path='train.csv'\n",
    "import os\n",
    "if kaggle:\n",
    "    os.system('pip install neptune')\n",
    "    \n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "# models: https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "\n",
    "\n",
    "df=pd.read_csv(kaggle_path if kaggle else local_path)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keyword.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keyword.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>5477</td>\n",
       "      <td>flames</td>\n",
       "      <td>houstn</td>\n",
       "      <td>location: houstn keyword: flames text: that ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>3393</td>\n",
       "      <td>demolition</td>\n",
       "      <td>everywhere</td>\n",
       "      <td>location: everywhere keyword: demolition text:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>8553</td>\n",
       "      <td>screams</td>\n",
       "      <td>San Juan, Puerto Rico</td>\n",
       "      <td>location: San Juan, Puerto Rico keyword: screa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>2480</td>\n",
       "      <td>collided</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location:  keyword: collided text: 16 dead in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>642</td>\n",
       "      <td>arsonist</td>\n",
       "      <td>United States</td>\n",
       "      <td>location: United States keyword: arsonist text...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>4335</td>\n",
       "      <td>dust storm</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>location: Atlanta, GA keyword: dust storm text...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>5162</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location:  keyword: fatalities text: EXCLUSIVE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>10422</td>\n",
       "      <td>whirlwind</td>\n",
       "      <td>Florida</td>\n",
       "      <td>location: Florida keyword: whirlwind text: Set...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>5381</td>\n",
       "      <td>fire truck</td>\n",
       "      <td>Saipan, CNMI</td>\n",
       "      <td>location: Saipan, CNMI keyword: fire truck tex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>3916</td>\n",
       "      <td>devastated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location:  keyword: devastated text: Obama Dec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     keyword               location  \\\n",
       "3849   5477      flames                 houstn   \n",
       "2357   3393  demolition             everywhere   \n",
       "5989   8553     screams  San Juan, Puerto Rico   \n",
       "1719   2480    collided                    NaN   \n",
       "443     642    arsonist          United States   \n",
       "3020   4335  dust storm            Atlanta, GA   \n",
       "3616   5162  fatalities                    NaN   \n",
       "7282  10422   whirlwind                Florida   \n",
       "3789   5381  fire truck           Saipan, CNMI   \n",
       "2726   3916  devastated                    NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "3849  location: houstn keyword: flames text: that ne...       0  \n",
       "2357  location: everywhere keyword: demolition text:...       0  \n",
       "5989  location: San Juan, Puerto Rico keyword: screa...       0  \n",
       "1719  location:  keyword: collided text: 16 dead in ...       1  \n",
       "443   location: United States keyword: arsonist text...       0  \n",
       "3020  location: Atlanta, GA keyword: dust storm text...       1  \n",
       "3616  location:  keyword: fatalities text: EXCLUSIVE...       1  \n",
       "7282  location: Florida keyword: whirlwind text: Set...       0  \n",
       "3789  location: Saipan, CNMI keyword: fire truck tex...       1  \n",
       "2726  location:  keyword: devastated text: Obama Dec...       1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str replaye %20 to space\n",
    "\n",
    "def prepare_df(df):\n",
    "    df=df.copy()\n",
    "    df.keyword=df.keyword.str.replace('%20',' ')\n",
    "    \n",
    "    # enrich text with location and text, when they are not null\n",
    "    df['text']='location: ' + df['location'].fillna('') + ' keyword: ' +  df['keyword'].fillna('') + ' text: ' + df['text']\n",
    "    return df\n",
    "\n",
    "df=prepare_df(df)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset and dataloader\n",
    "\n",
    "SEQ_LEN = 50\n",
    "KEYWORD_MAX_SEQ_LEN=3\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text=self.df.iloc[idx]['text']\n",
    "\n",
    "        input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        if (len(input_ids)<SEQ_LEN):\n",
    "            input_ids=input_ids+[0]*(SEQ_LEN-len(input_ids))\n",
    "            attention_mask=attention_mask+[0]*(SEQ_LEN-len(attention_mask))\n",
    "        elif (len(input_ids)>SEQ_LEN):\n",
    "            input_ids=input_ids[:SEQ_LEN]\n",
    "            attention_mask=attention_mask[:SEQ_LEN]\n",
    "\n",
    "        \n",
    "        keyword=self.df.iloc[idx]['keyword']\n",
    "        keyword_ids = tokenizer.encode(keyword, add_special_tokens=True)\n",
    "        if (len(keyword_ids)<KEYWORD_MAX_SEQ_LEN):\n",
    "            keyword_ids=keyword_ids+[0]*(KEYWORD_MAX_SEQ_LEN-len(keyword_ids))\n",
    "        elif (len(keyword_ids)>KEYWORD_MAX_SEQ_LEN):\n",
    "            keyword_ids=keyword_ids[:KEYWORD_MAX_SEQ_LEN]\n",
    "\n",
    "        if self.test:\n",
    "            return torch.tensor(input_ids), torch.tensor(attention_mask), torch.tensor(keyword_ids)\n",
    "        else:\n",
    "            label=self.df.iloc[idx]['target']\n",
    "            return torch.tensor(input_ids), torch.tensor(label), torch.tensor(attention_mask), torch.tensor(keyword_ids)\n",
    "        \n",
    "train_dataset = Dataset(train_df)\n",
    "valid_dataset = Dataset(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape torch.Size([32, 30])\n",
      "yb.shape torch.Size([32])\n",
      "att_mask.shape torch.Size([32, 30])\n",
      "keywords.shape torch.Size([32, 3])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ClassifierModel(torch.nn.Module):\n",
    "    def __init__(self, p_dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.model = DistilBertModel.from_pretrained('distilbert-base-cased')\n",
    "        self.linear1 = torch.nn.Linear(768, 2)\n",
    "        \n",
    "    def forward(self, x, attention_mask=None, keywords=None):\n",
    "        output = self.model(x, attention_mask=attention_mask)[\"last_hidden_state\"]\n",
    "        pooled_output = torch.mean(output, dim=1)\n",
    "        output = self.linear1(pooled_output)\n",
    "        return output\n",
    "    \n",
    "my_model=ClassifierModel(p_dropout=0.5)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "for xb, yb, att_mask, keywords in train_dataloader:\n",
    "    print(\"xb.shape\", xb.shape)\n",
    "    print(\"yb.shape\", yb.shape)\n",
    "    print(\"att_mask.shape\", att_mask.shape)\n",
    "    print(\"keywords.shape\", keywords.shape)\n",
    "    print(my_model(xb, attention_mask=att_mask, keywords=keywords).shape)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.AdamW(my_model.parameters(), lr=0.0001)\n",
    "loss_fn=torch.nn.CrossEntropyLoss()\n",
    "import neptune\n",
    "\n",
    "class Learner():\n",
    "    def __init__(self, model, optimizer, loss_fn, scheduler, batch_size=32):\n",
    "        self.model=model\n",
    "        self.optimizer=optimizer\n",
    "        self.loss_fn=loss_fn\n",
    "        self.scheduler=scheduler\n",
    "        self.device=torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device=torch.device(\"cuda\")\n",
    "        #elif torch.backends.mps.is_available():\n",
    "        #    self.device=torch.device(\"mps\")\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.run=neptune.init_run(\n",
    "            project=\"bernd.heidemann/clickbait-classification\",\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzNjBlYzVkNi0zZTUwLTQ1ODYtODhlNC02NDUxNDg0MDdjNzUifQ==\",\n",
    "        )\n",
    "        self.batch_size=batch_size\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def fit(self, lr=0.001, epochs=10):\n",
    "        self.run[\"parameters\"] = {\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": self.batch_size,\n",
    "        }\n",
    "        bar = tqdm(total=len(self.train_dataloader) * epochs, desc=\"Training\")\n",
    "        bar.set_description(\"Epoch 0/{}\".format(epochs))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()            \n",
    "            for xb, yb, att_mask, keywords in self.train_dataloader:\n",
    "                \n",
    "                xb=xb.to(self.device)\n",
    "                yb=yb.to(self.device)\n",
    "                att_mask=att_mask.to(self.device)\n",
    "                keywords=keywords.to(self.device)\n",
    "                pred=self.model(xb, attention_mask=att_mask, keywords=keywords)\n",
    "                loss=self.loss_fn(pred, yb)\n",
    "                self.run[\"train_loss\"].log(loss.item())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                bar.update(1)\n",
    "            self.scheduler.step()\n",
    "            self.model.eval()\n",
    "            # log current state to neptune\n",
    "            metrics=self.get_accuracy()\n",
    "            self.run[\"valid_accuracy\"].log(metrics[\"accuracy\"])\n",
    "            self.run[\"valid_loss\"].log(metrics[\"loss\"])\n",
    "            \n",
    "                \n",
    "    def get_accuracy(self):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct=0\n",
    "            losses=[]\n",
    "            for xb, yb, att_mask, keywords in self.valid_dataloader:\n",
    "                xb=xb.to(self.device)\n",
    "                yb=yb.to(self.device)\n",
    "                att_mask=att_mask.to(self.device)\n",
    "                keywords=keywords.to(self.device)\n",
    "                pred=self.model(xb, attention_mask=att_mask, keywords=keywords)\n",
    "                loss=self.loss_fn(pred, yb)\n",
    "                losses.append(loss.item())\n",
    "                pred=torch.argmax(pred, dim=1)\n",
    "                correct+=torch.sum(pred==yb).item()\n",
    "            return {\n",
    "                \"accuracy\": correct/len(valid_dataset),\n",
    "                \"loss\": np.mean(losses)\n",
    "            }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/qjs6b9wn4zx7nh630c4my9lw0000gn/T/ipykernel_57068/4131680193.py:18: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n",
      "  self.run=neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/bernd.heidemann/clickbait-classification/e/CLIC-79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8992b1ffd6bf4d66a7bdc5beaf9aa760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 5, eta_min=0.0001)\n",
    "\n",
    "my_model=ClassifierModel(p_dropout=0.5)\n",
    "learner=Learner(my_model, optimizer, loss_fn, scheduler, batch_size=128)\n",
    "learner.fit(lr=0.0001, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8266579120157583, 'loss': 0.4035767888029416}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1680</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New: Two giant cranes holding a bridge collaps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>5451</td>\n",
       "      <td>first%20responders</td>\n",
       "      <td>Tennessee, USA</td>\n",
       "      <td>Please pray for employees  residents and first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>4586</td>\n",
       "      <td>emergency%20plan</td>\n",
       "      <td>In erotic world</td>\n",
       "      <td>Calgary takes another beating from summer stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>7620</td>\n",
       "      <td>pandemonium</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>On the Christie Hillside: Game 4 - Pandemonium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>8548</td>\n",
       "      <td>screams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one of my fav lydia screams is in 4x11 when sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             keyword          location  \\\n",
       "513   1680   bridge%20collapse               NaN   \n",
       "1619  5451  first%20responders    Tennessee, USA   \n",
       "1391  4586    emergency%20plan  In erotic world    \n",
       "2281  7620         pandemonium   Toronto, Canada   \n",
       "2561  8548             screams               NaN   \n",
       "\n",
       "                                                   text  \n",
       "513   New: Two giant cranes holding a bridge collaps...  \n",
       "1619  Please pray for employees  residents and first...  \n",
       "1391  Calgary takes another beating from summer stor...  \n",
       "2281  On the Christie Hillside: Game 4 - Pandemonium...  \n",
       "2561  one of my fav lydia screams is in 4x11 when sh...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_test_path='test.csv'\n",
    "kaggle_test_path='/kaggle/input/nlp-getting-started/test.csv'\n",
    "\n",
    "df_submission_test_data=pd.read_csv(kaggle_test_path if kaggle else local_test_path)\n",
    "df_submission_test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_test_data=prepare_df(df_submission_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "test_dataset=Dataset(df_submission_test_data, test=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for xb, att_mask, keywords in test_loader:\n",
    "    xb=xb.to(learner.device)\n",
    "    att_mask=att_mask.to(learner.device)\n",
    "    keywords=keywords.to(learner.device)\n",
    "    print(xb.shape)\n",
    "    print(att_mask.shape)\n",
    "    print(my_model(xb, attention_mask=att_mask, keywords=keywords).shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "\n",
    "for xb, att_mask, keywords in test_loader:\n",
    "    xb=xb.to(learner.device)\n",
    "    att_mask=att_mask.to(learner.device)\n",
    "    keywords=keywords.to(learner.device)\n",
    "    pred=my_model(xb, attention_mask=att_mask, keywords=keywords)\n",
    "    pred=torch.argmax(pred, dim=1)\n",
    "    predictions+=pred.tolist()\n",
    "\n",
    "df_submission_test_data['target']=predictions\n",
    "df_submission_test_data[['id', 'target']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.797"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
